{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKjxEi3/dMHFaoZBTzQR+F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uguazelli/Blockchain-Multisig/blob/main/sequential_chaining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updated version to work with LangChain 0.1.x+ and langchain-openai"
      ],
      "metadata": {
        "id": "kwNJc-UeUvBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chaining (Multi-Step Prompting)\n",
        "Use multi-step chaining if:\n",
        "* You need very reliable results\n",
        "* You want to inject logic or validation between steps\n",
        "* You're building an agent or a dynamic flow"
      ],
      "metadata": {
        "id": "pXUPB1N-Wq31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pip Install"
      ],
      "metadata": {
        "id": "fshoYtRPIUSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -U langchain langchain-community langchain-openai\n",
        "!pip install pydantic\n"
      ],
      "metadata": {
        "id": "Wpx5QpG8MMwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZC400R5IYQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JKD2nukCIeWY"
      },
      "outputs": [],
      "source": [
        "# Imports'\n",
        "from google.colab import userdata\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI # âœ… use langchain_openai, not community\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get API key from Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "FEfmiyaPKSuY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LLM (completion model like GPT-3.5-turbo-instruct and level of creativity 0.6 of 1)\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", api_key=api_key, temperature=0.6)"
      ],
      "metadata": {
        "id": "Mh1Rk_yBLyMP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test simple call\n",
        "response = llm.invoke(\"Tell me a fun fact about AI\")\n",
        "print(\"Simple Response:\", response)"
      ],
      "metadata": {
        "id": "ye_QVrUgRQZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Name\n",
        "name_prompt = PromptTemplate.from_template(\n",
        "    \"I want to open a {topic} restaurant. Suggest a really nice name. Return just one name.\"\n",
        ")\n",
        "\n",
        "# Step 2: Slogan\n",
        "slogan_prompt = PromptTemplate.from_template(\n",
        "    \"Create a catchy slogan for a restaurant named '{name}'.\"\n",
        ")\n",
        "\n",
        "# Step 3: Concept\n",
        "concept_prompt = PromptTemplate.from_template(\n",
        "    \"Describe the branding and interior design concept for a restaurant named '{name}' with the slogan '{slogan}'.\"\n",
        ")\n",
        "\n",
        "# Step 4: Logo Description\n",
        "logo_prompt = PromptTemplate.from_template(\n",
        "    \"Based on the name '{name}' and slogan '{slogan}', describe an ideal logo: colors, icon, font, and style.\"\n",
        ")\n",
        "\n",
        "# Step 5: Image Generation Prompt (for DALLÂ·E or Midjourney)\n",
        "image_prompt = PromptTemplate.from_template(\n",
        "    \"Create a visual prompt for an image generation tool to design the logo: '{logo_description}'\"\n",
        ")"
      ],
      "metadata": {
        "id": "0PthmDMcVA0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build each step\n",
        "step1 = name_prompt | llm\n",
        "step2 = lambda name: slogan_prompt | llm\n",
        "step3 = lambda name, slogan: concept_prompt | llm\n",
        "step4 = lambda name, slogan: logo_prompt | llm\n",
        "step5 = lambda logo_description: image_prompt | llm"
      ],
      "metadata": {
        "id": "JD2XE-QLe347"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap in RunnableSequence\n",
        "def full_pipeline(topic: str):\n",
        "    name = step1.invoke({\"topic\": topic}).strip()\n",
        "    slogan = (slogan_prompt | llm).invoke({\"name\": name}).strip()\n",
        "    concept = (concept_prompt | llm).invoke({\"name\": name, \"slogan\": slogan}).strip()\n",
        "    logo = (logo_prompt | llm).invoke({\"name\": name, \"slogan\": slogan}).strip()\n",
        "    image_prompt_text = (image_prompt | llm).invoke({\"logo_description\": logo}).strip()\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"slogan\": slogan,\n",
        "        \"concept\": concept,\n",
        "        \"logo_description\": logo,\n",
        "        \"image_prompt\": image_prompt_text\n",
        "    }"
      ],
      "metadata": {
        "id": "viWHxJrbe_9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "result = full_pipeline(\"Brazilian\")\n",
        "for key, value in result.items():\n",
        "    print(f\"\\nðŸ”¹ {key.upper()}:\\n{value}\")"
      ],
      "metadata": {
        "id": "JC5GnQ6dfFq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}